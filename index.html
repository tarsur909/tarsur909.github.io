
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 120px;
      position: relative;
    }

    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/logo12.png">
  <title>Tarun Suresh</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-167314770-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-167314770-1');
  </script>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Tarun Suresh</name>
              </p>
              <p> I'm a third-year undergraduate student in the Computer Science Department at the University of Illinois, Urbana-Champaign advised by <a href="https://misailo.cs.illinois.edu/" target="_blank">Prof. Sasa Misailovic</a>, <a href="https://ggndpsngh.github.io/" target="_blank">Prof. Gagandeep Singh</a>, and <a href="http://blender.cs.illinois.edu/hengji.html" target="_blank">Prof. Heng Ji</a>.
              </p>
              
              <p align=center>
                <a href="mailto:tarsur909@gmail.com" target="_blank">Email</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/tarsur909/" target="_blank">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Yxx6B5YAAAAJ&hl=en" target="_blank">Google Scholar</a> 
              </p>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research</heading>
              <p>
                My research lies at the intersection of deep learning, systems, and formal methods/programming languages. I am deeply interested in building efficient, scalable, and reliable AI systems. 
              </p>
              <p>
                I'm currently researching:
              </p>
              <p>
                - Structured Output Generation with Large Language Models (LLMs)
              </p>
              <p>
                - Embedding Models, Re-Ranking, and Retrieval-Augmented Generation
              </p>
              <p>
                - LLMs for Software Development
              </p>
              <p>
                - Reinforcement Learning from Human Feedback (RLHF) and Preference-Based Reinforcement Learning (PBRL)
              </p>
              <p>
                - Formal Verification and Adversarial Robustness of Deep Neural Networks 
              </p>
            </td>
          </tr>
          
          
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Papers</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr>
            <td width="25%">
              <div class="one">
                  <a href="images/rabbit.png" target="_blank"><img style="width:100%;max-width:100%" src='images/rabbit.png'></a>
              </div>
              
            </td>
            <td valign="top" width="75%">
              <a href="https://openreview.net/pdf/3ae0ff26b47452acd364e62b3457ac330522843a.pdf" target="_blank">
                  <papertitle>Relational Verification Leaps Forward with RABBit</papertitle>
              </a>
              <br>
              <strong>Tarun Suresh*</strong>,              
              <a href="https://debangshu-banerjee.github.io/" target="_blank">Debangshu Banerjee*</a>,
              <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>
              <br>
              <em>NeurIPS 2024</em>
              <br>
              [<a href="https://openreview.net/forum?id=W5U3XB1C11" target="_blank">Paper</a>][<a href="https://openreview.net/pdf/3ae0ff26b47452acd364e62b3457ac330522843a.pdf" target="_blank">PDF</a>]
              <br>
              <p>We introduce new gradient-based joint optimization algorithms and combine them into a scalable Branch-and-Bound-based verifier RABBit for precisely verifying relational properties defined over Deep Neural Networks, such as robustness against universal adversarial perturbations (UAP).</p>
              </td>
          </tr>   

          <tr>
            <td width="25%">
              <div class="one">
                  <a href="images/irs.png" target="_blank"><img style="width:100%;max-width:100%" src='images/irs.png'></a>
              </div>
              
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2305.19521" target="_blank">
                  <papertitle>Incremental Randomized Smoothing Certification</papertitle>
              </a>
              <br>
              <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
              <strong>Tarun Suresh</strong>,              
              <a href="https://debangshu-banerjee.github.io/" target="_blank">Debangshu Banerjee</a>,
              <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>,
              <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>
              <br>
              <em>ICLR 2024</em>
              <br>
              [<a href="https://arxiv.org/abs/2305.19521" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2305.19521" target="_blank">PDF</a>]
              <br>
              <p>We present IRS, the first probabilistic approach for incremental robustness re-certification of Deep Neural Networks after approximation (pruning, quantization) </p>
              </td>
          </tr>   

          <tr>
            <td width="25%">
              <div class="one">
                  <a href="images/lpw.png" target="_blank"><img style="width:100%;max-width:100%" src='images/lpw.png'></a>
              </div>
              
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2305.19521" target="_blank">
                  <papertitle>Is Watermarking LLM Generated Code Robust?</papertitle>
              </a>
              <br>
              <strong>Tarun Suresh</strong>,  
              <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
              <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>,            
              <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>
              <br>
              <em>Tiny ICLR 2024 (Oral Presentation)</em>
              <br>
              [<a href="https://arxiv.org/abs/2403.17983" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2403.17983" target="_blank">PDF</a>]
              <br>
              <p>We present the first study of the robustness of existing watermarking techniques on code generated by large language models and propose a parsing-based algorithm that easily removes these watermarks via semantic preserving transformations of the code. </p>
              </td>
          </tr>   
           

            <tr>
              <td width="25%">
                <div class="one">
                    <a href="images/cornstack.png" target="_blank"><img style="width:100%;max-width:100%" src='images/cornstack.png'></a>
                </div>
                
              </td>
              <td valign="top" width="75%">
                <a href="https://gangiswag.github.io/code-embed/" target="_blank">
                    <papertitle>CoRNStack: High-Quality Contrastive Data for Better Code Retrieval and Reranking</papertitle>
                </a>
                <br>
                <strong>Tarun Suresh*</strong>,  
                <a href="" target="_blank">Revanth Gangi Reddy*</a>,
                <a href="" target="_blank">Yifei Xu</a>,
                <a href="" target="_blank">Zach Nussbaum</a>,
                <a href="" target="_blank">Andriy Mulyar</a>,
                <a href="" target="_blank">Brandon Duderstadt</a>,
                <a href="https://blender.cs.illinois.edu/hengji.html" target="_blank">Heng Ji</a>
                <br>
                <em>Under Review</em>
                <br>
                [<a href="https://gangiswag.github.io/cornstack" target="_blank">Blog Post</a>][<span>Paper Coming Soon!</span>]
                <br>
                <p>We introduce CoRNStack, a large-scale, high-quality contrastive training dataset for code that spans multiple programming languages. We demonstrate that contrastive training of embedding models using CoRNStack leads to state-of-the-art performance across a variety of code retrieval tasks.</p>
                </td>
            </tr>  

            <tr>
              <td width="25%">
                <div class="one">
                    <a href="images/syncode.png" target="_blank"><img style="width:100%;max-width:100%" src='images/syncode.png'></a>
                </div>
                
              </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2403.01632" target="_blank">
                  <papertitle>SynCode: LLM Generation with Grammar Augmentation</papertitle>
              </a>
              <br>
              <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
              <strong>Tarun Suresh</strong>,  
              <a href="" target="_blank">Hangoo Kang</a>,
              <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>,
              <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>
              <br>
              <em>Under Review</em>
              <br>
              [<a href="https://arxiv.org/abs/2403.01632" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2403.01632" target="_blank">PDF</a>][<a href="https://github.com/uiuc-focal-lab/syncode" target="_blank">Code</a>]
              <br>
              <p>SynCode is a novel framework for the grammar-guided generation of Large Language Models (LLMs) that is scalable to general-purpose programming languages and has soundness and completeness guarantees. SynCode reduces syntax errors by 96-100% for various languages (JSON, Python, Go) and enables 1.5x-10x faster LLM inference than existing approaches. </p>
              </td>
          </tr>               
        

          <tr>
            <td width="25%">
              <div class="one">
                  <a href="images/itergen.png" target="_blank"><img style="width:100%;max-width:100%" src='images/itergen.png'></a>
              </div>
              
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2410.07295" target="_blank">
                  <papertitle>IterGen: Iterative Structured LLM Generation</papertitle>
              </a>
              <br>
              <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
              <a href="" target="_blank">Rohan Gumaste</a>,
              <strong>Tarun Suresh</strong>,  
              <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>,            
              <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>
              <br>
              <em>Under Review</em>
              <br>
              [<a href="https://arxiv.org/abs/2410.07295" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2410.07295" target="_blank">PDF</a>]
              <br>
              <p>IterGen is a framework that enables users to define and enforce semantic constraints into LLM output and efficiently backtrack and re-sample during LLM generation until these constraints are satisfied. IterGen improves LLM-generated SQL accuracy by 18% and eliminates LLM privacy leakage.</p>
              </td>
          </tr>   

          <tr>
            <td width="25%">
              <div class="one">
                  <a href="images/tar.png" target="_blank"><img style="width:100%;max-width:100%" src='images/tar.png'></a>
              </div>
              
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2408.00761" target="_blank">
                  <papertitle>Tamper-Resistant Safeguards for Open-Weight LLMs</papertitle>
              </a>
              <br>
              <a href="https://rishub-tamirisa.github.io/research/" target="_blank">Rishub Tamirisa</a>,
              <a href="" target="_blank">Bhrugu Bharathi</a>,
              <a href="https://longphan.ai/" target="_blank">Long Phan</a>,
              <a href="https://www.andyzhou.ai/" target="_blank">Andy Zhou</a>,
              <a href="" target="_blank">Alice Gatti</a>,
              <strong>Tarun Suresh</strong>,  
              <a href="" target="_blank">Maxwell Lin</a>,
              <a href="" target="_blank">Justin Wang</a>,
              <a href="" target="_blank">Rowan Wang</a>,
              <a href="https://arel.ai/" target="_blank">Ron Arel</a>,
              <a href="https://andyzoujm.github.io/" target="_blank">Andy Zou</a>,
              <a href="https://dawnsong.io/" target="_blank">Dawn Song</a>,  
              <a href="https://aisecure.github.io/" target="_blank">Bo Li</a>,  
              <a href="https://people.eecs.berkeley.edu/~hendrycks/" target="_blank">Dan Hendrycks</a>,  
              <a href="" target="_blank">Mantas Mazeika</a>
              <br>
              <em>Under Review</em>
              <br>
              [<a href="https://arxiv.org/abs/2408.00761" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2408.00761" target="_blank">PDF</a>]
              <br>
              <p>We develop a method, called TAR, for building tamper-resistant safeguards into open-weight LLMs such that adversaries cannot remove the safeguards even after thousands of steps of fine-tuning. In extensive evaluations and red teaming analyses, we find that our method greatly improves tamper-resistance while preserving benign capabilities.</p>
              </td>
          </tr>   

          <tr>
            <td width="25%">
              <div class="one">
                  <a href="images/prc.png" target="_blank"><img style="width:100%;max-width:100%" src='images/prc.png'></a>
              </div>
              
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/abs/2401.00330v3" target="_blank">
                  <papertitle>Two-Step Offline Preference-Based Reinforcement Learning with Constrained Actions</papertitle>
              </a>
              <br>
              <a href="https://xuyinglun.com/" target="_blank">Yinglun Xu</a>,
              <strong>Tarun Suresh</strong>,  
              <a href="" target="_blank">Rohan Gumaste</a>,
              <a href="" target="_blank">David Zhu</a>,
              <a href="" target="_blank">Ruirui Li</a>,
              <a href="" target="_blank">Zhengyang Wang</a>,
              <a href="" target="_blank">Haoming Jiang</a>,
              <a href="" target="_blank">Xianfeng Tang</a>,
              <a href="" target="_blank">Qingyu Yin</a>,
              <a href="" target="_blank">Monica Xiao Cheng</a>,
              <a href="" target="_blank">Qi Zheng</a>,
              <a href="" target="_blank">Chao Zhang</a>,
              <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>
              <br>
              <em>Under Review</em>
              <br>
              [<a href="https://arxiv.org/abs/2401.00330v3" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2401.00330v3" target="_blank">PDF</a>]
              <br>
              <p> To address challenges from the risk of reward hacking and the complexity of reinforcement learning during preference-based reinforcement learning, we develop a novel two-step learning method called PRC.  The high-level idea is to limit the reinforcement learning agent to optimize over a constrained action space that excludes out-of-distribution state-actions, are unreliable and increase the complexity of the reinforcement learning problem at the second step. </address></p>
              </td>
          </tr>   
        

          <tr>
            <td width="25%">
              <div class="one">
                  <a href="images/cdnn.png" target="_blank"><img style="width:100%;max-width:100%" src='images/cdnn.png'></a>
              </div>
              
            </td>
            <td valign="top" width="75%">
              <a href="https://misailo.web.engr.illinois.edu/papers/icml-workshop-23-incver.pdf" target="_blank">
                  <papertitle>Towards Continuous Verification of DNNs</papertitle>
              </a>
              <br>
              <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
              <a href="https://debangshu-banerjee.github.io/" target="_blank">Debangshu Banerjee</a>,
              <strong>Tarun Suresh</strong>,  
              <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>,            
              <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>
              <br>
              <em>WFML @ ICML 2023</em>
              <br>
              [<a href="https://misailo.web.engr.illinois.edu/papers/icml-workshop-23-incver.pdf" target="_blank">Paper</a>][<a href="https://misailo.web.engr.illinois.edu/papers/icml-workshop-23-incver.pdf" target="_blank">PDF</a>]
              <br>
              <p>We propose efficient deterministic formal verifiers to speed up DNN re-verification after pruning, quantization, or fine-tuning. </p>
              </td>
          </tr>  
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  <br><a href="https://jonbarron.info/">Template from here</a></font>
              </p>
            </td>
          </tr>
        </table>
        

        </td>
    </tr>
  </table>
</body>

</html>

