
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 120px;
      position: relative;
    }

    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/logo12.png">
  <title>Tarun Suresh</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-167314770-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-167314770-1');
  </script>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Tarun Suresh</name>
              </p>
              <p> I'm a third-year undergraduate student in the Computer Science Department at the University of Illinois, Urbana-Champaign (UIUC). I work with <a href="https://misailo.cs.illinois.edu/" target="_blank">Prof. Sasa Misailovic (UIUC)</a>, <a href="https://ggndpsngh.github.io/" target="_blank">Prof. Gagandeep Singh (UIUC)</a>, <a href="https://theory.stanford.edu/~aiken/" target="_blank">Prof. Alex Aiken (Stanford)</a>, and <a href="http://blender.cs.illinois.edu/hengji.html" target="_blank">Prof. Heng Ji (UIUC)</a>.
              </p>
              
              <p align=center>
                <a href="mailto:tarsur909@gmail.com" target="_blank">Email</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/tarsur909/" target="_blank">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Yxx6B5YAAAAJ&hl=en" target="_blank">Google Scholar</a> 
              </p>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research</heading>
              <p>
                My research is at the intersection of deep learning, formal methods, and programming languages. I am largely interested in improving the capabilities of AI systems in challenging, real-world coding, math, and logical reasoning tasks. 
              </p>
              <p>
                I'm currently researching:
              </p>
              <p>
                - Deep Learning for Program Synthesis and Code Semantics Understanding
              </p>
              <p>
                - Tool Use with Language Models and Language Model-driven Software Engineering
              </p>
              <p>
                - LLM Post-Training (Preference and Reinforcement Finetuning) and Inference (Decoding, Reasoning, Search, Planning) Algorithms For Code
              </p>
              <p>
                - AI for Formal Methods and Formal Methods for AI
              </p>
            </td>
          </tr>
          
          
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Papers</heading>
            </td>
          </tr>
        </table>

        <!-- Constrained Generation of LLMs -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <div class="research-section">
                <h3 class="section-title" onclick="toggleSection('constrained-generation')" style="cursor: pointer; font-family: 'Lato', Verdana, Helvetica, sans-serif; font-size: 18px; font-weight: bold; color: #1772d0; margin-bottom: 10px;">
                  â–¼ Constrained Generation of LLMs
                </h3>
                <div id="constrained-generation" class="section-content">
                  
                  <table width="100%" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                      <td width="25%">
                        <div class="one">
                            <a href="images/dingo.png" target="_blank"><img style="width:100%;max-width:100%" src='images/dingo.png'></a>
                        </div>
                      </td>
                      <td valign="top" width="75%">
                        <a href="https://arxiv.org/abs/2505.23061" target="_blank">
                            <papertitle>DINGO: Constrained Inference for Diffusion LLMs</papertitle>
                        </a>
                        <br>
                        <strong>Tarun Suresh</strong>,  
                        <a href="https://debangshu-banerjee.github.io/" target="_blank">Debangshu Banerjee</a>,
                        <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
                        <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>,
                        <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>
                        <br>
                        <em>R2-FM @ ICML 2025</em>
                        <br>
                        [<a href="https://arxiv.org/abs/2505.23061" target="_blank">Paper</a>]
                        <br>
                        <p>We introduce DINGO, a novel constrained inference method for diffusion-based large language models that enables efficient generation while satisfying user-defined constraints. Our approach provides a principled way to incorporate constraints into the diffusion process, enabling more controllable and reliable LLM generation.</p>
                      </td>
                    </tr>

                    <tr>
                      <td width="25%">
                        <div class="one">
                            <a href="images/crane.png" target="_blank"><img style="width:100%;max-width:100%" src='images/crane.png'></a>
                        </div>
                      </td>
                      <td valign="top" width="75%">
                        <a href="https://arxiv.org/abs/2502.09061" target="_blank">
                            <papertitle>CRANE: Reasoning with Constrained LLM Generation</papertitle>
                        </a>
                        <br>
                        <a href="https://debangshu-banerjee.github.io/" target="_blank">Debangshu Banerjee*</a>,
                        <strong>Tarun Suresh*</strong>,  
                        <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
                        <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>,
                        <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>
                        <br>
                        <em>ICML 2025; Also at VerifAI @ ICLR 2025</em>
                        <br>
                        [<a href="https://arxiv.org/abs/2502.09061" target="_blank">Paper</a>]
                        <br>
                        <p>We show theoretically that constraining LLM generation to a fixed output grammar can reduce reasoning capabilities and by augmenting the grammar with additional production rules for CoT reasoning steps, we can preserve LLM expressivity. Building on these theoretical results, we introduce CRANE, a constrained decoding algorithm that only enforces the grammar when generating final answers and intermediate expressions, while keeping reasoning steps unconstrained. CRANE boosts accuracy by up to 10 percentage points on first-order logic generation and other symbolic reasoning tasks. </p>
                      </td>
                    </tr>

                    <tr>
                      <td width="25%">
                        <div class="one">
                            <a href="images/itergen.png" target="_blank"><img style="width:100%;max-width:100%" src='images/itergen.png'></a>
                        </div>
                      </td>
                      <td valign="top" width="75%">
                        <a href="https://arxiv.org/abs/2410.07295" target="_blank">
                            <papertitle>IterGen: Iterative Semantic-aware Structured LLM Generation with Backtracking</papertitle>
                        </a>
                        <br>
                        <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
                        <a href="" target="_blank">Rohan Gumaste</a>,
                        <strong>Tarun Suresh</strong>,  
                        <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>,            
                        <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>
                        <br>
                        <em>ICLR 2025</em>
                        <br>
                        [<a href="https://arxiv.org/abs/2410.07295" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2410.07295" target="_blank">PDF</a>]
                        <br>
                        <p>IterGen is a decoding algorithm which leverages grammar-based backtracking and selective rejection sampling to efficiently enforce user-defined semantic constraints into LLM output. IterGen improves LLM-generated SQL accuracy by 18% and eliminates LLM privacy leakage.</p>
                      </td>
                    </tr>

                    <tr>
                      <td width="25%">
                        <div class="one">
                            <a href="images/syncode.png" target="_blank"><img style="width:100%;max-width:100%" src='images/syncode.png'></a>
                        </div>
                      </td>
                      <td valign="top" width="75%">
                        <a href="https://arxiv.org/abs/2403.01632" target="_blank">
                            <papertitle>SynCode: LLM Generation with Grammar Augmentation</papertitle>
                        </a>
                        <br>
                        <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
                        <strong>Tarun Suresh</strong>,  
                        <a href="" target="_blank">Hangoo Kang</a>,
                        <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>,
                        <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>
                        <br>
                        <em>TMLR 2025</em>
                        <br>
                        [<a href="https://arxiv.org/abs/2403.01632" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2403.01632" target="_blank">PDF</a>][<a href="https://github.com/uiuc-focal-lab/syncode" target="_blank">Code</a>]
                        <br>
                        <p>SynCode is a novel framework for the grammar-guided generation of Large Language Models (LLMs) that is scalable to general-purpose programming languages and has soundness and completeness guarantees. SynCode reduces syntax errors by 96-100% for various languages (JSON, Python, Go) and enables 1.5x-10x faster LLM inference than existing approaches. </p>
                      </td>
                    </tr>
                  </table>
                  
                </div>
              </div>
            </td>
          </tr>
        </table>

        <!-- RLHF/Reward Modeling/Reward Hacking -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <div class="research-section">
                <h3 class="section-title" onclick="toggleSection('rlhf-reward')" style="cursor: pointer; font-family: 'Lato', Verdana, Helvetica, sans-serif; font-size: 18px; font-weight: bold; color: #1772d0; margin-bottom: 10px;">
                  â–¼ Reinforcement Learning, Reward Modeling, and Reward Hacking
                </h3>
                                 <div id="rlhf-reward" class="section-content">
                   
                   <table width="100%" border="0" cellspacing="0" cellpadding="20">
                     <tr>
                       <td width="25%">
                         <div class="one">
                             <a href="images/pet.png" target="_blank"><img style="width:100%;max-width:100%" src='images/pet.png'></a>
                         </div>
                       </td>
                       <td valign="top" width="75%">
                         <a href="https://arxiv.org/abs/2505.20556" target="_blank">
                             <papertitle>Learning a Pessimistic Reward Model in RLHF</papertitle>
                         </a>
                         <br>
                         <a href="https://xuyinglun.com/" target="_blank">Yinglun Xu</a>,
                         <a href="" target="_blank">Hangoo Kang</a>,
                         <strong>Tarun Suresh</strong>,  
                         <a href="" target="_blank">Yuxuan Wan</a>,
                         <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>
                         <br>
                         <em>In Submission</em>
                         <br>
                         [<a href="https://arxiv.org/abs/2505.20556" target="_blank">Paper</a>]
                         <br>
                         <p>We propose PET, a novel pessimistic reward fine-tuning method, to learn a pessimistic reward model robust against reward hacking in offline reinforcement learning from human feedback (RLHF). Our method shows that when optimizing a policy on a pessimistic reward model fine-tuned through PET, reward hacking can be prevented without relying on any regularization, enabling agents to greedily search for high-reward policies without suffering from reward hacking.</p>
                       </td>
                     </tr>

                     <tr>
                       <td width="25%">
                         <div class="one">
                             <a href="images/prc.png" target="_blank"><img style="width:100%;max-width:100%" src='images/prc.png'></a>
                         </div>
                       </td>
                       <td valign="top" width="75%">
                         <a href="https://arxiv.org/abs/2401.00330v3" target="_blank">
                             <papertitle>Two-Step Offline Preference-Based Reinforcement Learning with Constrained Actions</papertitle>
                         </a>
                         <br>
                         <a href="https://xuyinglun.com/" target="_blank">Yinglun Xu</a>,
                         <strong>Tarun Suresh</strong>,  
                         <a href="" target="_blank">Rohan Gumaste</a>,
                         <a href="" target="_blank">David Zhu</a>,
                         <a href="" target="_blank">Ruirui Li</a>,
                         <a href="" target="_blank">Zhengyang Wang</a>,
                         <a href="" target="_blank">Haoming Jiang</a>,
                         <a href="" target="_blank">Xianfeng Tang</a>,
                         <a href="" target="_blank">Qingyu Yin</a>,
                         <a href="" target="_blank">Monica Xiao Cheng</a>,
                         <a href="" target="_blank">Qi Zheng</a>,
                         <a href="" target="_blank">Chao Zhang</a>,
                         <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>
                         <br>
                         <em>Under Review</em>
                         <br>
                         [<a href="https://arxiv.org/abs/2401.00330v3" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2401.00330v3" target="_blank">PDF</a>]
                         <br>
                         <p> To address challenges from the risk of reward hacking and the complexity of reinforcement learning during preference-based reinforcement learning, we develop a novel two-step learning method called PRC.  The high-level idea is to limit the reinforcement learning agent to optimize over a constrained action space that excludes out-of-distribution state-actions, which are unreliable and increase the complexity of the reinforcement learning problem. </p>
                       </td>
                     </tr>
                   </table>
                  
                </div>
              </div>
            </td>
          </tr>
        </table>

        <!-- Deep Learning for PL/FM/SE -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <div class="research-section">
                <h3 class="section-title" onclick="toggleSection('dl-pl-fm-se')" style="cursor: pointer; font-family: 'Lato', Verdana, Helvetica, sans-serif; font-size: 18px; font-weight: bold; color: #1772d0; margin-bottom: 10px;">
                  â–¼ Language Models for Programming Synthesis, Optimization, and Verification and Software Development
                </h3>
                                 <div id="dl-pl-fm-se" class="section-content">
                   
                   <table width="100%" border="0" cellspacing="0" cellpadding="20">
                     <tr>
                       <td width="25%">
                         <div class="one">
                             <a href="images/codearc.png" target="_blank"><img style="width:100%;max-width:100%" src='images/codearc.png'></a>
                         </div>
                       </td>
                       <td valign="top" width="75%">
                         <a href="https://arxiv.org/abs/2503.23145" target="_blank">
                             <papertitle>CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis</papertitle>
                         </a>
                         <br>
                         <a href="https://anjiang-wei.github.io/" target="_blank">Anjiang Wei</a>,
                         <strong>Tarun Suresh</strong>,
                         <a href="" target="_blank">Jiannan Cao</a>,
                         <a href="" target="_blank">Naveen Kannan</a>,
                         <a href="" target="_blank">Yuheng Wu</a>,
                         <a href="" target="_blank">Kai Yan</a>,
                         <a href="" target="_blank">Thiago S. F. X. Teixeira</a>,
                         <a href="" target="_blank">Ke Wang</a>,
                         <a href="https://theory.stanford.edu/~aiken/" target="_blank">Alex Aiken</a>
                         <br>
                         <em>COLM 2025</em>
                         <br>
                         [<a href="https://arxiv.org/abs/2503.23145" target="_blank">Paper</a>][<a href="https://github.com/Anjiang-Wei/CodeARC" target="_blank">Code</a>]
                         <br>
                         <p>We propose CodeARC, the Code Abstraction and Reasoning Challenge, a new evaluation framework where agents interact with a hidden target function by querying it with new inputs, synthesizing candidate functions, and iteratively refining their solutions using a differential testing oracle. We construct the first large-scale benchmark for general-purpose inductive program synthesis, featuring 1114 functions. Among 18 models evaluated, o3-mini performs best with a success rate of 52.7%, highlighting the difficulty of this task.</p>
                       </td>
                     </tr>

                     <tr>
                       <td width="25%">
                         <div class="one">
                             <a href="images/cornstack.png" target="_blank"><img style="width:100%;max-width:100%" src='images/cornstack.png'></a>
                         </div>
                       </td>
                       <td valign="top" width="75%">
                         <a href="https://arxiv.org/abs/2412.01007" target="_blank">
                             <papertitle>CoRNStack: High-Quality Contrastive Data for Better Code Retrieval and Reranking</papertitle>
                         </a>
                         <br>
                         <strong>Tarun Suresh*</strong>,  
                         <a href="https://gangiswag.github.io/" target="_blank">Revanth Gangi Reddy*</a>,
                         <a href="" target="_blank">Yifei Xu</a>,
                         <a href="" target="_blank">Zach Nussbaum</a>,
                         <a href="https://andriymulyar.com/projects" target="_blank">Andriy Mulyar</a>,
                         <a href="https://www.nomad.garden/" target="_blank">Brandon Duderstadt</a>,
                         <a href="https://blender.cs.illinois.edu/hengji.html" target="_blank">Heng Ji</a>
                         <br>
                         <em>ICLR 2025</em>
                         <br>
                         [<a href="https://gangiswag.github.io/cornstack" target="_blank">Blog Post</a>][<a href="https://arxiv.org/pdf/2412.01007" target="_blank">Paper</a>][<a href="https://github.com/gangiswag/cornstack" target="_blank">Code</a>]
                         <br>
                         <p>We introduce CoRNStack, a large-scale, high-quality contrastive training dataset for code that spans multiple programming languages. We demonstrate that contrastive training of embedding models and LLM re-rankers using CoRNStack leads to state-of-the-art performance across a variety of code retrieval tasks. Notably, our lightweight retriever + re-ranker achieves state-of-the-art repoistory level bug localization on SWE-Bench over top automated software development frameworks.</p>
                       </td>
                     </tr>

                     <tr>
                       <td width="25%">
                         <div class="one">
                             <a href="images/swerank.png" target="_blank"><img style="width:100%;max-width:100%" src='images/swerank.png'></a>
                         </div>
                       </td>
                       <td valign="top" width="75%">
                         <a href="https://arxiv.org/abs/2505.07849" target="_blank">
                             <papertitle>SweRank: Software Issue Localization with Code Ranking</papertitle>
                         </a>
                         <br>
                         <a href="https://gangiswag.github.io/" target="_blank">Revanth Gangi Reddy</a>,
                         <strong>Tarun Suresh</strong>,
                         <a href="" target="_blank">JaeHyeok Doo</a>,
                         <a href="" target="_blank">Ye Liu</a>,
                         <a href="" target="_blank">Xuan Phi Nguyen</a>,
                         <a href="" target="_blank">Yingbo Zhou</a>,
                         <a href="" target="_blank">Semih Yavuz</a>,
                         <a href="" target="_blank">Caiming Xiong</a>,
                         <a href="https://blender.cs.illinois.edu/hengji.html" target="_blank">Heng Ji</a>,
                         <a href="" target="_blank">Shafiq Joty</a>
                         <br>
                         <em>In Submission</em>
                         <br>
                         [<a href="https://arxiv.org/abs/2505.07849" target="_blank">Paper</a>][<a href="https://github.com/SalesforceAIResearch/SweRank" target="_blank">Code</a>]
                         <br>
                         <p>We present SweRank, a novel approach for software issue localization that leverages code ranking techniques to identify relevant code segments for bug fixing. Our method significantly improves localization accuracy by effectively ranking code files and functions based on their relevance to reported software issues.</p>
                       </td>
                     </tr>

                     <tr>
                       <td width="25%">
                         <div class="one">
                             <a href="images/superopt.png" target="_blank"><img style="width:100%;max-width:100%" src='images/superopt.png'></a>
                         </div>
                       </td>
                       <td valign="top" width="75%">
                         <a href="https://arxiv.org/abs/2505.11480" target="_blank">
                             <papertitle>Improving Assembly Code Performance with Large Language Models via Reinforcement Learning</papertitle>
                         </a>
                         <br>
                         <a href="https://anjiang-wei.github.io/" target="_blank">Anjiang Wei</a>,
                         <strong>Tarun Suresh</strong>,
                         <a href="" target="_blank">Huanmi Tan</a>,
                         <a href="https://xuyinglun.com/" target="_blank">Yinglun Xu</a>,
                         <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>,
                         <a href="" target="_blank">Ke Wang</a>,
                         <a href="https://theory.stanford.edu/~aiken/" target="_blank">Alex Aiken</a>
                         <br>
                         <em>In Submission</em>
                         <br>
                         [<a href="https://arxiv.org/abs/2505.11480" target="_blank">Paper</a>]
                         <br>
                         <p>We present a reinforcement learning framework that trains LLMs using Proximal Policy Optimization (PPO) to optimize assembly code performance. Our model, Qwen2.5-Coder-7B-PPO, achieves 96.0% test pass rates and an average speedup of 1.47x over the gcc -O3 baseline on a benchmark of 8,072 real-world programs, demonstrating that reinforcement learning can unlock the potential of LLMs to serve as effective optimizers for assembly code performance.</p>
                       </td>
                     </tr>
                   </table>
                  
                </div>
              </div>
            </td>
          </tr>
        </table>

        <!-- Neural Network Robustness and Verification -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <div class="research-section">
                <h3 class="section-title" onclick="toggleSection('nn-robustness')" style="cursor: pointer; font-family: 'Lato', Verdana, Helvetica, sans-serif; font-size: 18px; font-weight: bold; color: #1772d0; margin-bottom: 10px;">
                  â–¼ Neural Network Robustness and Verification
                </h3>
                                 <div id="nn-robustness" class="section-content">
                   
                   <table width="100%" border="0" cellspacing="0" cellpadding="20">
                     <tr>
                       <td width="25%">
                         <div class="one">
                             <a href="images/tar.png" target="_blank"><img style="width:100%;max-width:100%" src='images/tar.png'></a>
                         </div>
            </td>
            </td>
            
                       </td>
            
                       <td valign="top" width="75%">
                         <a href="https://arxiv.org/abs/2408.00761" target="_blank">
                             <papertitle>Tamper-Resistant Safeguards for Open-Weight LLMs</papertitle>
                         </a>
                         <br>
                         <a href="https://rishub-tamirisa.github.io/research/" target="_blank">Rishub Tamirisa</a>,
                         <a href="" target="_blank">Bhrugu Bharathi</a>,
                         <a href="https://longphan.ai/" target="_blank">Long Phan</a>,
                         <a href="https://www.andyzhou.ai/" target="_blank">Andy Zhou</a>,
                         <a href="" target="_blank">Alice Gatti</a>,
                         <strong>Tarun Suresh</strong>,  
                         <a href="" target="_blank">Maxwell Lin</a>,
                         <a href="" target="_blank">Justin Wang</a>,
                         <a href="" target="_blank">Rowan Wang</a>,
                         <a href="https://arel.ai/" target="_blank">Ron Arel</a>,
                         <a href="https://andyzoujm.github.io/" target="_blank">Andy Zou</a>,
                         <a href="https://dawnsong.io/" target="_blank">Dawn Song</a>,  
                         <a href="https://aisecure.github.io/" target="_blank">Bo Li</a>,  
                         <a href="https://people.eecs.berkeley.edu/~hendrycks/" target="_blank">Dan Hendrycks</a>,  
                         <a href="" target="_blank">Mantas Mazeika</a>
                         <br>
                         <em>ICLR 2025</em>
                         <br>
                         [<a href="https://arxiv.org/abs/2408.00761" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2408.00761" target="_blank">PDF</a>]
                         <br>
                         <p>We develop a method, called TAR, for building tamper-resistant safeguards into open-weight LLMs such that adversaries cannot remove the safeguards even after thousands of steps of fine-tuning. In extensive evaluations and red teaming analyses, we find that our method greatly improves tamper-resistance while preserving benign capabilities.</p>
                       </td>
                     </tr>

                     <tr>
                       <td width="25%">
                         <div class="one">
                             <a href="images/rabbit.png" target="_blank"><img style="width:100%;max-width:100%" src='images/rabbit.png'></a>
                         </div>
                       </td>
                       <td valign="top" width="75%">
                         <a href="https://openreview.net/pdf/3ae0ff26b47452acd364e62b3457ac330522843a.pdf" target="_blank">
                             <papertitle>Relational Verification Leaps Forward with RABBit</papertitle>
                         </a>
                         <br>
                         <strong>Tarun Suresh*</strong>,              
                         <a href="https://debangshu-banerjee.github.io/" target="_blank">Debangshu Banerjee*</a>,
                         <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>
                         <br>
                         <em>NeurIPS 2024</em>
                         <br>
                         [<a href="https://openreview.net/forum?id=W5U3XB1C11" target="_blank">Paper</a>][<a href="https://openreview.net/pdf/3ae0ff26b47452acd364e62b3457ac330522843a.pdf" target="_blank">PDF</a>][<a href="https://github.com/uiuc-focal-lab/RABBit" target="_blank">Code</a>]
                         <br>
                         <p> We introduce a GPU-accelerated, Branch-and-Bound-based verifier RABBit for formally verifying hyperproperties, such as ensembles, conformal prediction, and robustness, defined over multiple executions of Deep Neural Networks. RABBit improves neural network verified accuracy by 8% over state-of-the-art verifiers within the same compute budget. </p>
                       </td>
                     </tr>

                     <tr>
                       <td width="25%">
                         <div class="one">
                             <a href="images/irs.png" target="_blank"><img style="width:100%;max-width:100%" src='images/irs.png'></a>
                         </div>
                       </td>
                       <td valign="top" width="75%">
                         <a href="https://arxiv.org/abs/2305.19521" target="_blank">
                             <papertitle>Incremental Randomized Smoothing Certification</papertitle>
                         </a>
                         <br>
                         <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
                         <strong>Tarun Suresh</strong>,              
                         <a href="https://debangshu-banerjee.github.io/" target="_blank">Debangshu Banerjee</a>,
                         <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>,
                         <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>
                         <br>
                         <em>ICLR 2024</em>
                         <br>
                         [<a href="https://arxiv.org/abs/2305.19521" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2305.19521" target="_blank">PDF</a>][<a href="https://github.com/uiuc-arc/Incremental-DNN-Verification" target="_blank">Code</a>]
                         <br>
                         <p>We present IRS, the first probabilistic approach for 5x faster robustness re-certification of Deep Neural Networks after model compression (pruning, quantization) or fine-tuning </p>
                       </td>
                     </tr>

                     <tr>
                       <td width="25%">
                         <div class="one">
                             <a href="images/lpw.png" target="_blank"><img style="width:100%;max-width:100%" src='images/lpw.png'></a>
                         </div>
                       </td>
                       <td valign="top" width="75%">
                         <a href="https://arxiv.org/abs/2305.19521" target="_blank">
                             <papertitle>Is Watermarking LLM Generated Code Robust?</papertitle>
                         </a>
                         <br>
                         <strong>Tarun Suresh</strong>,  
                         <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
                         <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>,            
                         <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>
                         <br>
                         <em>Tiny ICLR 2024 (Oral Presentation)</em>
                         <br>
                         [<a href="https://arxiv.org/abs/2403.17983" target="_blank">Paper</a>][<a href="https://arxiv.org/pdf/2403.17983" target="_blank">PDF</a>][<a href="https://github.com/uiuc-arc/llm-code-watermark" target="_blank">Code</a>]
                         <br>
                         <p>We present the first study of the robustness of existing watermarking techniques on code generated by large language models and propose a parsing-based algorithm that easily removes these watermarks via semantic preserving transformations of the code. </p>
                       </td>
                     </tr>

                     <tr>
                       <td width="25%">
                         <div class="one">
                             <a href="images/cdnn.png" target="_blank"><img style="width:100%;max-width:100%" src='images/cdnn.png'></a>
                         </div>
                       </td>
                       <td valign="top" width="75%">
                         <a href="https://misailo.web.engr.illinois.edu/papers/icml-workshop-23-incver.pdf" target="_blank">
                             <papertitle>Towards Continuous Verification of DNNs</papertitle>
                         </a>
                         <br>
                         <a href="https://shubhamugare.github.io/" target="_blank">Shubham Ugare</a>,
                         <a href="https://debangshu-banerjee.github.io/" target="_blank">Debangshu Banerjee</a>,
                         <strong>Tarun Suresh</strong>,  
                         <a href="https://ggndpsngh.github.io/" target="_blank">Gagandeep Singh</a>,            
                         <a href="https://misailo.cs.illinois.edu/" target="_blank">Sasa Misailovic</a>
                         <br>
                         <em>WFML @ ICML 2023</em>
                         <br>
                         [<a href="https://misailo.web.engr.illinois.edu/papers/icml-workshop-23-incver.pdf" target="_blank">Paper</a>][<a href="https://misailo.web.engr.illinois.edu/papers/icml-workshop-23-incver.pdf" target="_blank">PDF</a>][<a href="https://github.com/uiuc-arc/Incremental-DNN-Verification" target="_blank">Code</a>]
                         <br>
                         <p>We propose efficient deterministic formal verifiers to speed up DNN re-verification after pruning, quantization, or fine-tuning. </p>
                       </td>
                     </tr>
                   </table>
                  
                </div>
              </div>
            </td>
          </tr>
        </table>

        <script>
          function toggleSection(sectionId) {
            const content = document.getElementById(sectionId);
            const title = content.previousElementSibling;
            
            if (content.style.display === 'none') {
              content.style.display = 'block';
              title.innerHTML = title.innerHTML.replace('â–¶', 'â–¼');
            } else {
              content.style.display = 'none';
              title.innerHTML = title.innerHTML.replace('â–¼', 'â–¶');
            }
          }

          // Initialize all sections as expanded
          document.addEventListener('DOMContentLoaded', function() {
            const sections = ['constrained-generation', 'rlhf-reward', 'dl-pl-fm-se', 'nn-robustness'];
            sections.forEach(function(sectionId) {
              const content = document.getElementById(sectionId);
              if (content) {
                content.style.display = 'block';
              }
            });
          });
                 </script>
         
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  <br><a href="https://jonbarron.info/">Template from here</a></font>
              </p>
            </td>
          </tr>
        </table>

        </td>
    </tr>
  </table>
</body>

</html>

